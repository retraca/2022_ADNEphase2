{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Reshape, Activation, Conv1D, MaxPooling1D, Dropout, LSTM, Bidirectional, GRU, BatchNormalization, ELU, Attention, LSTM, Input, UpSampling1D, TimeDistributed, SpatialDropout2D, SpatialDropout1D\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "plt.style.use('seaborn-poster')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = './data/trainAlunos/'\n",
    "list_npy_files = glob.glob(dir + '*.npy')\n",
    "fnames_dataset_train = tf.data.Dataset.from_tensor_slices(list_npy_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = './data/validacaoAlunos/'\n",
    "list_npy_files = glob.glob(dir + '*.npy')\n",
    "fnames_dataset_validacao = tf.data.Dataset.from_tensor_slices(list_npy_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>\n"
     ]
    }
   ],
   "source": [
    "print(fnames_dataset_train)\n",
    "#print(fnames_dataset_validacao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_npy(fname):\n",
    "    \"\"\"fname should be a npy file\"\"\"\n",
    "    fname = fname.decode()\n",
    "    recData = np.load(fname)\n",
    "    return recData.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_raw_train = fnames_dataset_train.map(lambda x: tf.numpy_function(read_npy, [x], [tf.float32]))\n",
    "dataset_raw_validacao = fnames_dataset_validacao.map(lambda x: tf.numpy_function(read_npy, [x], [tf.float32]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 33655), dtype=float32, numpy=\n",
       " array([[341., 256.,  71., ..., -78., 130., 235.],\n",
       "        [  4.,   4.,   4., ...,   3.,   3.,   3.]], dtype=float32)>,)"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it3 = iter(dataset_raw_train)\n",
    "ex3 = next(it3)\n",
    "ex3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2773"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min= 5000\n",
    "for i in iter(dataset_raw_train):\n",
    "    #print(i[0].shape[1])\n",
    "    if i[0].shape[1] < min:\n",
    "        min = i[0].shape[1]\n",
    "    #break\n",
    "    \n",
    "min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ISTO Ã‰ APENAS PARA O FEEDFORWARD, NOS OUTROS PODEMOS DAR O SINAL COMPLETO\n",
    "dataset_cuted_train = dataset_raw_train.map(lambda x: x[:,(tf.shape(x)[1]-2000):tf.shape(x)[1]])\n",
    "dataset_cuted_validacao = dataset_raw_train.map(lambda x: x[:,(tf.shape(x)[1]-2000):tf.shape(x)[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 2000])"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it3 = iter(dataset_cuted_train)\n",
    "ex3 = next(it3)\n",
    "ex3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_length= 1000\n",
    "frame_step = 10\n",
    "\n",
    "def stft(x):\n",
    "    return tf.signal.stft(\n",
    "    x,\n",
    "    frame_length,\n",
    "    frame_step,\n",
    "    fft_length=None,\n",
    "    window_fn=tf.signal.hann_window,\n",
    "    pad_end=False,\n",
    "    name=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2x_train = dataset_cuted_train.map(lambda x: (tf.math.abs(tf.signal.stft(signals = x[0], frame_length = 256, frame_step = 128)), x[1]))\n",
    "dataset2x_validacao = dataset_cuted_validacao.map(lambda x: (tf.math.abs(tf.signal.stft(signals = x[0], frame_length = 256, frame_step = 128)), x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(14, 129), dtype=float32, numpy=\n",
       " array([[4.0799033e+03, 1.2272309e+04, 7.2162002e+03, ..., 1.3904767e+02,\n",
       "         2.7887966e+01, 1.8205566e+01],\n",
       "        [4.2699473e+03, 1.2871683e+04, 1.0095986e+04, ..., 4.6013741e+01,\n",
       "         1.1352508e+02, 6.6249756e+01],\n",
       "        [4.5610225e+03, 7.2023442e+03, 1.5412860e+04, ..., 4.9293308e+01,\n",
       "         8.5428505e+01, 2.5179688e+01],\n",
       "        ...,\n",
       "        [6.9241626e+03, 8.8304102e+03, 2.1321293e+04, ..., 8.2463585e+01,\n",
       "         6.7195831e+01, 4.9052734e+01],\n",
       "        [1.7521475e+04, 5.6102633e+04, 7.5388734e+04, ..., 1.1511120e+01,\n",
       "         7.8482269e+01, 9.6849609e+01],\n",
       "        [1.3976577e+03, 9.1582391e+04, 2.6074452e+05, ..., 9.0046486e+01,\n",
       "         9.5586662e+01, 3.4563965e+01]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2000,), dtype=float32, numpy=array([4., 4., 4., ..., 3., 3., 3.], dtype=float32)>)"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it3 = iter(dataset2x_train)\n",
    "ex3 = next(it3)\n",
    "ex3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "\n",
    "dataset_b_train = dataset2x_train.batch(batch_size)\n",
    "dataset_b_validacao = dataset2x_validacao.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 14, 129), dtype=float32, numpy=\n",
       " array([[[4.07990332e+03, 1.22723086e+04, 7.21620020e+03, ...,\n",
       "          1.39047668e+02, 2.78879662e+01, 1.82055664e+01],\n",
       "         [4.26994727e+03, 1.28716826e+04, 1.00959863e+04, ...,\n",
       "          4.60137405e+01, 1.13525078e+02, 6.62497559e+01],\n",
       "         [4.56102246e+03, 7.20234424e+03, 1.54128604e+04, ...,\n",
       "          4.92933083e+01, 8.54285049e+01, 2.51796875e+01],\n",
       "         ...,\n",
       "         [6.92416260e+03, 8.83041016e+03, 2.13212930e+04, ...,\n",
       "          8.24635849e+01, 6.71958313e+01, 4.90527344e+01],\n",
       "         [1.75214746e+04, 5.61026328e+04, 7.53887344e+04, ...,\n",
       "          1.15111198e+01, 7.84822693e+01, 9.68496094e+01],\n",
       "         [1.39765771e+03, 9.15823906e+04, 2.60744516e+05, ...,\n",
       "          9.00464859e+01, 9.55866623e+01, 3.45639648e+01]],\n",
       " \n",
       "        [[5.17522021e+03, 7.37476709e+03, 6.08029883e+03, ...,\n",
       "          4.44938354e+01, 5.00777893e+01, 4.51113281e+01],\n",
       "         [4.12469336e+03, 3.54550220e+03, 4.83382568e+03, ...,\n",
       "          2.89094219e+01, 7.95164337e+01, 9.53767090e+01],\n",
       "         [7.74828027e+03, 8.42108594e+03, 4.54426514e+03, ...,\n",
       "          3.47465286e+01, 6.87833557e+01, 1.04843018e+02],\n",
       "         ...,\n",
       "         [1.36371572e+04, 1.91854453e+04, 1.65550195e+04, ...,\n",
       "          9.01431732e+01, 2.68561578e+00, 3.74443359e+01],\n",
       "         [2.76324799e+02, 1.92276426e+04, 2.85871406e+04, ...,\n",
       "          7.83939896e+01, 1.04375076e+02, 1.33668365e+02],\n",
       "         [5.11916626e+02, 1.86406396e+03, 3.30143164e+04, ...,\n",
       "          7.55237427e+01, 5.22610664e+01, 1.29383545e+01]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2, 2000), dtype=float32, numpy=\n",
       " array([[4., 4., 4., ..., 3., 3., 3.],\n",
       "        [2., 2., 2., ..., 1., 1., 1.]], dtype=float32)>)"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it3 = iter(dataset_b_train)\n",
    "ex3 = next(it3)\n",
    "ex3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##########################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(keras.Input(shape=(14,129)))\n",
    "model.add(Flatten())\n",
    "\"\"\" model.add(Dense(10000))\n",
    "model.add(Activation(activation=\"relu\"))\n",
    "model.add(BatchNormalization()) \"\"\"\n",
    "model.add(Dense(32))\n",
    "model.add(Activation(activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(64))\n",
    "model.add(Activation(activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "\"\"\" model.add(Dense(16))\n",
    "model.add(Activation(activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(128))\n",
    "model.add(Activation(activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(256))\n",
    "model.add(Activation(activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25)) \"\"\"\n",
    "model.add(Dense(10000))\n",
    "model.add(Activation(activation=\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(5*2000))\n",
    "model.add(Reshape((2000,5)))\n",
    "model.add(Activation(activation=\"softmax\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_114\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_77 (Flatten)        (None, 1806)              0         \n",
      "                                                                 \n",
      " dense_251 (Dense)           (None, 32)                57824     \n",
      "                                                                 \n",
      " activation_81 (Activation)  (None, 32)                0         \n",
      "                                                                 \n",
      " batch_normalization_21 (Bat  (None, 32)               128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_71 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_252 (Dense)           (None, 64)                2112      \n",
      "                                                                 \n",
      " activation_82 (Activation)  (None, 64)                0         \n",
      "                                                                 \n",
      " batch_normalization_22 (Bat  (None, 64)               256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_72 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_253 (Dense)           (None, 10000)             650000    \n",
      "                                                                 \n",
      " activation_83 (Activation)  (None, 10000)             0         \n",
      "                                                                 \n",
      " batch_normalization_23 (Bat  (None, 10000)            40000     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_73 (Dropout)        (None, 10000)             0         \n",
      "                                                                 \n",
      " dense_254 (Dense)           (None, 10000)             100010000 \n",
      "                                                                 \n",
      " reshape_57 (Reshape)        (None, 2000, 5)           0         \n",
      "                                                                 \n",
      " activation_84 (Activation)  (None, 2000, 5)           0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 100,760,320\n",
      "Trainable params: 100,740,128\n",
      "Non-trainable params: 20,192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n",
      "Epoch 1/10\n",
      " 221/1250 [====>.........................] - ETA: 13:17 - loss: 4.9938 - sparse_categorical_accuracy: 0.3360"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "print(\"[INFO] training network...\")\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer='adam',\n",
    "\tmetrics=[\"sparse_categorical_accuracy\"])\n",
    "H = model.fit(dataset_b_train, validation_data=dataset_b_validacao, batch_size=batch_size, epochs=EPOCHS )\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic cut\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dynamic_train = dataset_raw_train.map(lambda x: ((tf.shape(x)[1],tf.math.abs(tf.signal.stft(signals = x[0], frame_length = 256, frame_step = 128))),x[1]))\n",
    "dataset_dynamic_validacao = dataset_raw_validacao.map(lambda x: ((tf.shape(x)[1],tf.math.abs(tf.signal.stft(signals = x[0], frame_length = 256, frame_step = 128))),x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((<tf.Tensor: shape=(), dtype=int32, numpy=33655>,\n",
       "  <tf.Tensor: shape=(261, 129), dtype=float32, numpy=\n",
       "  array([[1.4234689e+04, 2.1549543e+04, 1.2858118e+04, ..., 7.5617584e+01,\n",
       "          1.2463839e+02, 1.9126709e+02],\n",
       "         [1.9105453e+04, 5.7239227e+04, 9.1444367e+04, ..., 1.1629249e+02,\n",
       "          1.4762794e+02, 2.3898633e+02],\n",
       "         [1.2337761e+04, 5.3582078e+04, 5.8043648e+04, ..., 1.1228875e+02,\n",
       "          5.6664654e+01, 2.8786133e+01],\n",
       "         ...,\n",
       "         [7.0647515e+03, 9.3874521e+03, 9.4922295e+03, ..., 2.7618443e+01,\n",
       "          3.3404732e+01, 3.9996582e+01],\n",
       "         [4.9324038e+03, 3.2865582e+04, 5.2553291e+03, ..., 7.0156136e+01,\n",
       "          8.7945480e+01, 2.7856934e+01],\n",
       "         [8.7604219e+03, 9.0686250e+04, 2.5793308e+05, ..., 4.9519798e+01,\n",
       "          9.7960144e+01, 3.3261719e+01]], dtype=float32)>),\n",
       " <tf.Tensor: shape=(33655,), dtype=float32, numpy=array([4., 4., 4., ..., 3., 3., 3.], dtype=float32)>)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it3 = iter(dataset_dynamic_train)\n",
    "ex3 = next(it3)\n",
    "ex3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "k=129\n",
    "dataset_pb_train = dataset_dynamic_train.padded_batch(batch_size, padded_shapes=(([], tf.TensorShape([None, k])),[None,]))\n",
    "dataset_pb_validacao = dataset_dynamic_validacao.padded_batch(batch_size, padded_shapes=(([], tf.TensorShape([None, k])),[None,]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((<tf.Tensor: shape=(2,), dtype=int32, numpy=array([33655, 23500])>,\n",
       "  <tf.Tensor: shape=(2, 261, 129), dtype=float32, numpy=\n",
       "  array([[[1.4234689e+04, 2.1549543e+04, 1.2858118e+04, ...,\n",
       "           7.5617584e+01, 1.2463839e+02, 1.9126709e+02],\n",
       "          [1.9105453e+04, 5.7239227e+04, 9.1444367e+04, ...,\n",
       "           1.1629249e+02, 1.4762794e+02, 2.3898633e+02],\n",
       "          [1.2337761e+04, 5.3582078e+04, 5.8043648e+04, ...,\n",
       "           1.1228875e+02, 5.6664654e+01, 2.8786133e+01],\n",
       "          ...,\n",
       "          [7.0647515e+03, 9.3874521e+03, 9.4922295e+03, ...,\n",
       "           2.7618443e+01, 3.3404732e+01, 3.9996582e+01],\n",
       "          [4.9324038e+03, 3.2865582e+04, 5.2553291e+03, ...,\n",
       "           7.0156136e+01, 8.7945480e+01, 2.7856934e+01],\n",
       "          [8.7604219e+03, 9.0686250e+04, 2.5793308e+05, ...,\n",
       "           4.9519798e+01, 9.7960144e+01, 3.3261719e+01]],\n",
       "  \n",
       "         [[9.4902051e+03, 1.6352716e+04, 2.0621682e+04, ...,\n",
       "           2.8047775e+01, 5.8838417e+01, 5.6687012e+01],\n",
       "          [6.2759673e+03, 1.6723230e+04, 3.9835254e+04, ...,\n",
       "           1.0322031e+02, 5.6750019e+01, 3.5373535e+01],\n",
       "          [5.3068550e+03, 5.0074590e+03, 1.6452344e+04, ...,\n",
       "           4.7681896e+01, 4.9298588e+01, 4.9234863e+01],\n",
       "          ...,\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "           0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "           0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
       "          [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
       "           0.0000000e+00, 0.0000000e+00, 0.0000000e+00]]], dtype=float32)>),\n",
       " <tf.Tensor: shape=(2, 33655), dtype=float32, numpy=\n",
       " array([[4., 4., 4., ..., 3., 3., 3.],\n",
       "        [4., 4., 4., ..., 0., 0., 0.]], dtype=float32)>)"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it3 = iter(dataset_pb_train)\n",
    "ex3 = next(it3)\n",
    "ex3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs= Input(shape=(None, 129), name=\"inputs\")\n",
    "inputs_L = Input(shape=[], name=\"inputs2\")\n",
    "layer= Conv1D(filters=32, kernel_size=2, padding=\"same\")(inputs)\n",
    "layer = MaxPooling1D(pool_size=1, strides=1)(layer)\n",
    "#layer = SpatialDropout1D(rate=0.2)(layer)\n",
    "#layer= Conv1D(filters=64, kernel_size=2, padding=\"same\")(layer)\n",
    "#layer= MaxPooling1D(pool_size=1, strides=1)(layer)\n",
    "layer= SpatialDropout1D(rate=0.2)(layer)\n",
    "layer = TimeDistributed(Dense(50, activation=\"relu\"))(layer)\n",
    "#layer= LSTM(units=128, return_sequences=True)(layer)\n",
    "layer= Reshape((-1,5))(layer)\n",
    "layer= UpSampling1D(size=10)(layer)\n",
    "L= tf.cast(tf.reduce_max(inputs_L), tf.int32)\n",
    "output= layer[:,:L]\n",
    "\"\"\" layer = TimeDistributed(Dense(50))(layer)\n",
    "layer= Activation(activation=\"softmax\")(layer)\n",
    "layer= Reshape((-1,5))(layer)\n",
    "layer = UpSampling1D(size=10)(layer)\n",
    "\n",
    "\"\"\"\n",
    "L= tf.cast(tf.reduce_max(inputs_L), tf.int32) \n",
    "output= layer[:,:L]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_24\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " inputs (InputLayer)            [(None, None, 129)]  0           []                               \n",
      "                                                                                                  \n",
      " conv1d_59 (Conv1D)             (None, None, 32)     8288        ['inputs[0][0]']                 \n",
      "                                                                                                  \n",
      " max_pooling1d_42 (MaxPooling1D  (None, None, 32)    0           ['conv1d_59[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " spatial_dropout1d_20 (SpatialD  (None, None, 32)    0           ['max_pooling1d_42[0][0]']       \n",
      " ropout1D)                                                                                        \n",
      "                                                                                                  \n",
      " time_distributed_26 (TimeDistr  (None, None, 50)    1650        ['spatial_dropout1d_20[0][0]']   \n",
      " ibuted)                                                                                          \n",
      "                                                                                                  \n",
      " inputs2 (InputLayer)           [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " reshape_49 (Reshape)           (None, None, 5)      0           ['time_distributed_26[0][0]']    \n",
      "                                                                                                  \n",
      " tf.math.reduce_max_20 (TFOpLam  ()                  0           ['inputs2[0][0]']                \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " up_sampling1d_22 (UpSampling1D  (None, None, 5)     0           ['reshape_49[0][0]']             \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.cast_20 (TFOpLambda)        ()                   0           ['tf.math.reduce_max_20[0][0]']  \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_22 (S  (None, None, 5)     0           ['up_sampling1d_22[0][0]',       \n",
      " licingOpLambda)                                                  'tf.cast_20[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 9,938\n",
      "Trainable params: 9,938\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 26100, 5), dtype=float32, numpy=\n",
       "array([[[    0.     ,  4756.991  ,     0.     ,  8752.468  ,\n",
       "          3012.1616 ],\n",
       "        [    0.     ,  4756.991  ,     0.     ,  8752.468  ,\n",
       "          3012.1616 ],\n",
       "        [    0.     ,  4756.991  ,     0.     ,  8752.468  ,\n",
       "          3012.1616 ],\n",
       "        ...,\n",
       "        [34197.582  ,     0.     ,     0.     , 21827.71   ,\n",
       "         81259.28   ],\n",
       "        [34197.582  ,     0.     ,     0.     , 21827.71   ,\n",
       "         81259.28   ],\n",
       "        [34197.582  ,     0.     ,     0.     , 21827.71   ,\n",
       "         81259.28   ]],\n",
       "\n",
       "       [[    0.     ,     0.     ,   905.27856, 11808.939  ,\n",
       "          4368.596  ],\n",
       "        [    0.     ,     0.     ,   905.27856, 11808.939  ,\n",
       "          4368.596  ],\n",
       "        [    0.     ,     0.     ,   905.27856, 11808.939  ,\n",
       "          4368.596  ],\n",
       "        ...,\n",
       "        [    0.     ,     0.     ,     0.     ,     0.     ,\n",
       "             0.     ],\n",
       "        [    0.     ,     0.     ,     0.     ,     0.     ,\n",
       "             0.     ],\n",
       "        [    0.     ,     0.     ,     0.     ,     0.     ,\n",
       "             0.     ]]], dtype=float32)>"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(inputs=(inputs_L, inputs), outputs=output)\n",
    "o=model(ex3[0])\n",
    "model.summary()\n",
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'Equal' defined at (most recent call last):\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 664, in launch_instance\n      app.start()\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 583, in start\n      self.io_loop.start()\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 153, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\asyncio\\base_events.py\", line 538, in run_forever\n      self._run_once()\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\asyncio\\base_events.py\", line 1782, in _run_once\n      handle._run()\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\asyncio\\events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n      ret = callback()\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n      self.run()\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n      yielded = self.gen.send(value)\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 361, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n      yielded = next(result)\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n      yielded = next(result)\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 541, in execute_request\n      user_expressions, allow_stdin,\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n      yielded = next(result)\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 300, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2858, in run_cell\n      raw_cell, store_history, silent, shell_futures)\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2886, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3063, in run_cell_async\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3254, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-366-9676414a901b>\", line 7, in <module>\n      H = model.fit(dataset_pb_train, batch_size=batch_size, epochs=EPOCHS )\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 864, in train_step\n      return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 957, in compute_metrics\n      self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 459, in update_state\n      metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\keras\\utils\\metrics_utils.py\", line 70, in decorated\n      update_op = update_state_fn(*args, **kwargs)\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\keras\\metrics.py\", line 178, in update_state_fn\n      return ag_update_state(*args, **kwargs)\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\keras\\metrics.py\", line 729, in update_state\n      matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\keras\\metrics.py\", line 4086, in sparse_categorical_accuracy\n      return tf.cast(tf.equal(y_true, y_pred), backend.floatx())\nNode: 'Equal'\nIncompatible shapes: [2,26100] vs. [2,33655]\n\t [[{{node Equal}}]] [Op:__inference_train_function_993229]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-366-9676414a901b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m model.compile(loss=\"sparse_categorical_crossentropy\", optimizer='adam',\n\u001b[0;32m      6\u001b[0m \tmetrics=[\"sparse_categorical_accuracy\"])\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_pb_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCHS\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;34m\"\"\" validation_data=dataset_pb_validacao, \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 55\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'Equal' defined at (most recent call last):\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 664, in launch_instance\n      app.start()\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 583, in start\n      self.io_loop.start()\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 153, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\asyncio\\base_events.py\", line 538, in run_forever\n      self._run_once()\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\asyncio\\base_events.py\", line 1782, in _run_once\n      handle._run()\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\asyncio\\events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n      ret = callback()\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n      self.run()\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n      yielded = self.gen.send(value)\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 361, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n      yielded = next(result)\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n      yielded = next(result)\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 541, in execute_request\n      user_expressions, allow_stdin,\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n      yielded = next(result)\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 300, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2858, in run_cell\n      raw_cell, store_history, silent, shell_futures)\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2886, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3063, in run_cell_async\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3254, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-366-9676414a901b>\", line 7, in <module>\n      H = model.fit(dataset_pb_train, batch_size=batch_size, epochs=EPOCHS )\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 864, in train_step\n      return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 957, in compute_metrics\n      self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 459, in update_state\n      metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\keras\\utils\\metrics_utils.py\", line 70, in decorated\n      update_op = update_state_fn(*args, **kwargs)\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\keras\\metrics.py\", line 178, in update_state_fn\n      return ag_update_state(*args, **kwargs)\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\keras\\metrics.py\", line 729, in update_state\n      matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\keras\\metrics.py\", line 4086, in sparse_categorical_accuracy\n      return tf.cast(tf.equal(y_true, y_pred), backend.floatx())\nNode: 'Equal'\nIncompatible shapes: [2,26100] vs. [2,33655]\n\t [[{{node Equal}}]] [Op:__inference_train_function_993229]"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "opt = SGD(learning_rate=0.01, momentum=0.9)\n",
    "metrics= [tf.keras.metrics.SparseCategoricalAccuracy()]\n",
    "print(\"[INFO] training network...\")\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer='adam',\n",
    "\tmetrics=[\"sparse_categorical_accuracy\"])\n",
    "H = model.fit(dataset_pb_train, batch_size=batch_size, epochs=EPOCHS )\n",
    "\"\"\" validation_data=dataset_pb_validacao, \"\"\" \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(keras.Input(shape=(None,129)))\n",
    "model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
    "#model.add(Attention(None))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(400))\n",
    "model.add(ELU())\n",
    "model.add(Dropout(0.2)) \n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_88\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_2 (Bidirectio  (None, None, 512)        790528    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_39 (Dropout)        (None, None, 512)         0         \n",
      "                                                                 \n",
      " dense_172 (Dense)           (None, None, 400)         205200    \n",
      "                                                                 \n",
      " elu (ELU)                   (None, None, 400)         0         \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        (None, None, 400)         0         \n",
      "                                                                 \n",
      " dense_173 (Dense)           (None, None, 5)           2005      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 997,733\n",
      "Trainable params: 997,733\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 200, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"sequential_95\" expects 1 input(s), but it received 2 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=int32>, <tf.Tensor 'IteratorGetNext:1' shape=(None, None, 129) dtype=float32>]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-265-6ebccde3237d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \"\"\" model.compile(loss=\"sparse_categorical_crossentropy\", optimizer='sgd',\n\u001b[0;32m      5\u001b[0m \tmetrics=[\"sparse_categorical_accuracy\"]) \"\"\"\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_pb_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdataset_pb_validacao\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCHS\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \"\"\" \n",
      "\u001b[1;32mc:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1146\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1147\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1148\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"c:\\Users\\ggpt9\\anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 200, in assert_input_compatibility\n        raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\n    ValueError: Layer \"sequential_95\" expects 1 input(s), but it received 2 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None,) dtype=int32>, <tf.Tensor 'IteratorGetNext:1' shape=(None, None, 129) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "\n",
    "print(\"[INFO] training network...\")\n",
    "\"\"\" model.compile(loss=\"sparse_categorical_crossentropy\", optimizer='sgd',\n",
    "\tmetrics=[\"sparse_categorical_accuracy\"]) \"\"\"\n",
    "H = model.fit(dataset_pb_train, validation_data=dataset_pb_validacao, batch_size=batch_size, epochs=EPOCHS )\n",
    "\n",
    "\"\"\" \n",
    "EPOCHS = 10\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=tf.keras.callbacks.EarlyStopping(verbose=1, patience=2),\n",
    ")\n",
    "\"\"\"\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9df27a627b87d6d3db0e78b7305fa2479238a9f6724039fbc95282cc5973468f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
