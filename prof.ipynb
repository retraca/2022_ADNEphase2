{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7d5862e",
   "metadata": {},
   "source": [
    "# Usar um pipeline para ler e processar um conjunto de ficheiros e usar esse mesmo pipeline como 'conjunto de treino' #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4d547269",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Reshape, Activation\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.style.use('seaborn-poster')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2971eed2",
   "metadata": {},
   "source": [
    "A api, tf.data.Dataset , permite criar um pipeline de leitura de ficheiros e seu eventual processamento, usando a função 'map':\n",
    "https://www.tensorflow.org/guide/data\n",
    ",\n",
    "https://www.tensorflow.org/guide/data_performance\n",
    ".\n",
    "\n",
    "Podemos fornecer diretamente um tfdata.Dataset ao método fit é uma forma muito eficiente de efetuar o treino de um modelo keras: https://www.tensorflow.org/guide/keras/train_and_evaluate#training_evaluation_from_tfdata_datasets\n",
    "\n",
    "\n",
    "No que se segue exemplificaremos a utilização desta api num conjunto de ficheiros do 2ª trabalho. O tf.data.Dataset permite criar 'batches' que podem sevir de inputs e labels a um modelo keras que faça a segmentação dos sons cardíacos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "630c45d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = './data/trainAlunos/'\n",
    "list_npy_files = glob.glob(dir + '*.npy')\n",
    "fnames_dataset_train = tf.data.Dataset.from_tensor_slices(list_npy_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3f5eedec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>\n"
     ]
    }
   ],
   "source": [
    "print(fnames_dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "62f555f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'./data/trainAlunos\\\\13918_AV_sigTarg.npy'>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it = iter(fnames_dataset_train)\n",
    "ex = next(it)\n",
    "ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "aae2c616",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = './data/validacaoAlunos/'\n",
    "list_npy_files = glob.glob(dir + '*.npy')\n",
    "fnames_dataset_validacao = tf.data.Dataset.from_tensor_slices(list_npy_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8d112146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>\n"
     ]
    }
   ],
   "source": [
    "print(fnames_dataset_validacao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "457d3be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'./data/validacaoAlunos\\\\14998_PV_sigTarg.npy'>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it = iter(fnames_dataset_validacao)\n",
    "ex = next(it)\n",
    "ex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad940278",
   "metadata": {},
   "source": [
    "Podemos aceder um a um aos elementos (ou batches de elementos) de um dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460a7bfa",
   "metadata": {},
   "source": [
    "A partir deste dataset inicial, fnames_dataset, vamos criar um cujo conteudo é o resultado de ler cada um dos ficheiros npy.\n",
    "\n",
    "Começamos por uma função auxiliar que vai ser usada pela função 'map' para ler o conteúdo de cada um dos ficheiros do fnames_dataset e criar um novo dataset com estes conteúdos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6ce321bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_npy(fname):\n",
    "    \"\"\"fname should be a npy file\"\"\"\n",
    "    fname = fname.decode()\n",
    "    recData = np.load(fname)\n",
    "    return recData.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "69f44ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_raw_train = fnames_dataset_train.map(lambda x: tf.numpy_function(read_npy, [x], [tf.float32]))\n",
    "dataset_raw_validacao = fnames_dataset_validacao.map(lambda x: tf.numpy_function(read_npy, [x], [tf.float32]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "f5627449",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "##ISTO É APENAS PARA O FEEDFORWARD, NOS OUTROS PODEMOS DAR O SINAL COMPLETO\n",
    "\n",
    "dataset_cuted_train = dataset_raw_train.map(lambda x: x[:,(tf.shape(x)[1]-2000):tf.shape(x)[1]])\n",
    "dataset_cuted_validacao = dataset_raw_train.map(lambda x: x[:,(tf.shape(x)[1]-2000):tf.shape(x)[1]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "421883de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2000), dtype=float32, numpy=\n",
       "array([[-266., -348., -379., ...,  -78.,  130.,  235.],\n",
       "       [   4.,    4.,    4., ...,    3.,    3.,    3.]], dtype=float32)>"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it3 = iter(dataset_cuted_train)\n",
    "ex3 = next(it3)\n",
    "ex3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28da430",
   "metadata": {},
   "source": [
    "Poderiamos também usar a função 'map' para separar inputs e targets e obter um dataset que produz um 'tuple', (input, target) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea63d2bb",
   "metadata": {},
   "source": [
    "O nosso dataset pode também produzir 'batches' em vez de exemplos individuais.  No nosso caso os exempos não tẽm todos o mesmo comprimento, assim, teremos de extender(por zeros??) os exemplos mais curtos de cada batch de modo a todos os exemplos do mesmo batch terem o mesmo comprimento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec4ca4b",
   "metadata": {},
   "source": [
    "    Poderiamos também usar a função map para aplicar a 'stft' aos inputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "db4c5d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_length= 1000\n",
    "frame_step = 10\n",
    "\n",
    "def stft(x):\n",
    "    return tf.signal.stft(\n",
    "    x,\n",
    "    frame_length,\n",
    "    frame_step,\n",
    "    fft_length=None,\n",
    "    window_fn=tf.signal.hann_window,\n",
    "    pad_end=False,\n",
    "    name=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "2f70ad0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' dataset_stft_train = dataset_cuted_train.map(lambda x: ((tf.shape(x)[1],tf.signal.stft(x[0], 256,128)),x[1]))\\ndataset_stft_validacao = dataset_cuted_validacao.map(lambda x: ((tf.shape(x)[1],tf.signal.stft(x[0], 256,128)),x[1]))\\n '"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#precisar nos outros pra guardar tamnaho do sinal\n",
    "\n",
    "\"\"\" \n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "3b62b46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2x_train = dataset_cuted_train.map(lambda x: (tf.math.abs(tf.signal.stft(signals = x[0], frame_length = 256, frame_step = 128)), x[1]))\n",
    "dataset2x_validacao = dataset_cuted_validacao.map(lambda x: (tf.math.abs(tf.signal.stft(signals = x[0], frame_length = 256, frame_step = 128)), x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "dbc1f71e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(14, 129), dtype=float32, numpy=\n",
       " array([[4.0799033e+03, 1.2272309e+04, 7.2162002e+03, ..., 1.3904767e+02,\n",
       "         2.7887966e+01, 1.8205566e+01],\n",
       "        [4.2699473e+03, 1.2871683e+04, 1.0095986e+04, ..., 4.6013741e+01,\n",
       "         1.1352508e+02, 6.6249756e+01],\n",
       "        [4.5610225e+03, 7.2023442e+03, 1.5412860e+04, ..., 4.9293308e+01,\n",
       "         8.5428505e+01, 2.5179688e+01],\n",
       "        ...,\n",
       "        [6.9241626e+03, 8.8304102e+03, 2.1321293e+04, ..., 8.2463585e+01,\n",
       "         6.7195831e+01, 4.9052734e+01],\n",
       "        [1.7521475e+04, 5.6102633e+04, 7.5388734e+04, ..., 1.1511120e+01,\n",
       "         7.8482269e+01, 9.6849609e+01],\n",
       "        [1.3976577e+03, 9.1582391e+04, 2.6074452e+05, ..., 9.0046486e+01,\n",
       "         9.5586662e+01, 3.4563965e+01]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2000,), dtype=float32, numpy=array([4., 4., 4., ..., 3., 3., 3.], dtype=float32)>)"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it3 = iter(dataset2x_train)\n",
    "ex3 = next(it3)\n",
    "ex3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "dbe91b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' #precisar nos outros\\n\\nbatch_size = 2\\nk=129\\ndataset_pb_train = dataset_stft_train.padded_batch(batch_size, padded_shapes=(([], tf.TensorShape([None, k])),[None,]))\\ndataset_pb_validacao = dataset_stft_validacao.padded_batch(batch_size, padded_shapes=(([], tf.TensorShape([None, k])),[None,])) '"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" #precisar nos outros\n",
    "\n",
    "batch_size = 2\n",
    "k=129\n",
    "dataset_pb_train = dataset_stft_train.padded_batch(batch_size, padded_shapes=(([], tf.TensorShape([None, k])),[None,]))\n",
    "dataset_pb_validacao = dataset_stft_validacao.padded_batch(batch_size, padded_shapes=(([], tf.TensorShape([None, k])),[None,])) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "86c38cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "\n",
    "dataset_pb_train = dataset2x_train.batch(batch_size)\n",
    "dataset_pb_validacao = dataset2x_validacao.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "43e0c941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(10, 14, 129), dtype=float32, numpy=\n",
       " array([[[4.07990332e+03, 1.22723086e+04, 7.21620020e+03, ...,\n",
       "          1.39047668e+02, 2.78879662e+01, 1.82055664e+01],\n",
       "         [4.26994727e+03, 1.28716826e+04, 1.00959863e+04, ...,\n",
       "          4.60137405e+01, 1.13525078e+02, 6.62497559e+01],\n",
       "         [4.56102246e+03, 7.20234424e+03, 1.54128604e+04, ...,\n",
       "          4.92933083e+01, 8.54285049e+01, 2.51796875e+01],\n",
       "         ...,\n",
       "         [6.92416260e+03, 8.83041016e+03, 2.13212930e+04, ...,\n",
       "          8.24635849e+01, 6.71958313e+01, 4.90527344e+01],\n",
       "         [1.75214746e+04, 5.61026328e+04, 7.53887344e+04, ...,\n",
       "          1.15111198e+01, 7.84822693e+01, 9.68496094e+01],\n",
       "         [1.39765771e+03, 9.15823906e+04, 2.60744516e+05, ...,\n",
       "          9.00464859e+01, 9.55866623e+01, 3.45639648e+01]],\n",
       " \n",
       "        [[5.17522021e+03, 7.37476709e+03, 6.08029883e+03, ...,\n",
       "          4.44938354e+01, 5.00777893e+01, 4.51113281e+01],\n",
       "         [4.12469336e+03, 3.54550220e+03, 4.83382568e+03, ...,\n",
       "          2.89094219e+01, 7.95164337e+01, 9.53767090e+01],\n",
       "         [7.74828027e+03, 8.42108594e+03, 4.54426514e+03, ...,\n",
       "          3.47465286e+01, 6.87833557e+01, 1.04843018e+02],\n",
       "         ...,\n",
       "         [1.36371572e+04, 1.91854453e+04, 1.65550195e+04, ...,\n",
       "          9.01431732e+01, 2.68561578e+00, 3.74443359e+01],\n",
       "         [2.76324799e+02, 1.92276426e+04, 2.85871406e+04, ...,\n",
       "          7.83939896e+01, 1.04375076e+02, 1.33668365e+02],\n",
       "         [5.11916626e+02, 1.86406396e+03, 3.30143164e+04, ...,\n",
       "          7.55237427e+01, 5.22610664e+01, 1.29383545e+01]],\n",
       " \n",
       "        [[2.69469946e+03, 6.93030859e+03, 3.95989404e+03, ...,\n",
       "          7.00685730e+01, 1.62963730e+02, 1.75923340e+02],\n",
       "         [1.05500771e+04, 1.49410137e+04, 1.48650547e+04, ...,\n",
       "          3.58754044e+01, 1.67462051e+02, 1.69704102e+02],\n",
       "         [5.41070801e+03, 6.38451367e+03, 2.00011060e+03, ...,\n",
       "          9.04330139e+01, 1.00309738e+02, 1.95370117e+02],\n",
       "         ...,\n",
       "         [5.45173389e+03, 9.57025098e+03, 1.72814434e+04, ...,\n",
       "          1.93762680e+02, 1.07390327e+02, 5.34467773e+01],\n",
       "         [2.89951147e+03, 8.78717969e+03, 1.31741719e+04, ...,\n",
       "          1.88444916e+02, 1.53813217e+02, 5.35075684e+01],\n",
       "         [7.79608594e+03, 2.00809219e+04, 4.94284727e+04, ...,\n",
       "          5.69730835e+01, 1.46879242e+02, 1.79561768e+02]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[2.68240332e+03, 3.93700732e+03, 2.63768140e+03, ...,\n",
       "          3.83643913e+01, 4.69117661e+01, 8.19643555e+01],\n",
       "         [1.19389990e+03, 2.26012817e+03, 2.07772534e+03, ...,\n",
       "          9.54289932e+01, 9.33333435e+01, 8.68049927e+01],\n",
       "         [3.39286475e+03, 2.91019678e+03, 3.90135522e+03, ...,\n",
       "          1.10590942e+02, 2.28698902e+01, 2.67066650e+01],\n",
       "         ...,\n",
       "         [1.55250305e+02, 3.28045361e+03, 5.11219727e+03, ...,\n",
       "          2.99327888e+01, 1.57501774e+01, 8.80072021e+00],\n",
       "         [4.87264709e+02, 9.45602539e+02, 1.93835864e+03, ...,\n",
       "          5.97083206e+01, 4.18859863e+01, 4.85107422e+00],\n",
       "         [5.00405957e+03, 3.98838013e+03, 2.33858643e+03, ...,\n",
       "          4.29017715e+01, 4.20332375e+01, 8.67382812e+00]],\n",
       " \n",
       "        [[1.42715469e+04, 3.33913647e+03, 2.15309570e+04, ...,\n",
       "          6.36082382e+01, 8.08122330e+01, 8.52036133e+01],\n",
       "         [4.02911621e+03, 8.32420996e+03, 6.03845898e+03, ...,\n",
       "          8.99201431e+01, 1.42728790e+02, 1.47646973e+02],\n",
       "         [1.32698369e+04, 9.37511426e+03, 6.63469775e+03, ...,\n",
       "          5.46589699e+01, 4.12909889e+01, 1.79296875e+00],\n",
       "         ...,\n",
       "         [4.64456348e+03, 7.90672900e+03, 1.39820325e+03, ...,\n",
       "          6.06273117e+01, 3.41240463e+01, 4.91608887e+01],\n",
       "         [1.28232119e+04, 4.15618799e+03, 1.16741191e+04, ...,\n",
       "          8.47041397e+01, 8.50856094e+01, 5.76845703e+01],\n",
       "         [4.63056172e+04, 8.97096250e+04, 1.47693484e+05, ...,\n",
       "          3.57946892e+01, 7.45006866e+01, 5.85214844e+01]],\n",
       " \n",
       "        [[1.56047205e+03, 3.39231567e+03, 2.63068604e+03, ...,\n",
       "          9.29291306e+01, 1.87858906e+01, 1.16820068e+01],\n",
       "         [1.29713672e+03, 1.29566333e+03, 2.39538330e+03, ...,\n",
       "          1.02611694e+01, 7.05334396e+01, 5.24752808e+01],\n",
       "         [3.30335181e+03, 2.96811475e+03, 2.41348779e+03, ...,\n",
       "          1.69617905e+02, 1.21578957e+02, 7.31352539e+01],\n",
       "         ...,\n",
       "         [6.65326758e+03, 4.34390967e+03, 6.26443311e+03, ...,\n",
       "          1.19218254e+01, 4.58402100e+01, 2.92626953e+01],\n",
       "         [5.99666406e+03, 6.87484814e+03, 7.63686719e+03, ...,\n",
       "          1.39141190e+02, 1.13395218e+02, 1.25601807e+02],\n",
       "         [2.98186016e+04, 5.11919453e+04, 1.05009281e+05, ...,\n",
       "          1.19828911e+02, 2.69876282e+02, 1.69165039e+02]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(10, 2000), dtype=float32, numpy=\n",
       " array([[4., 4., 4., ..., 3., 3., 3.],\n",
       "        [2., 2., 2., ..., 1., 1., 1.],\n",
       "        [4., 4., 4., ..., 3., 3., 3.],\n",
       "        ...,\n",
       "        [4., 4., 4., ..., 2., 2., 2.],\n",
       "        [2., 2., 2., ..., 1., 1., 1.],\n",
       "        [2., 2., 2., ..., 1., 1., 1.]], dtype=float32)>)"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it3 = iter(dataset_pb_train)\n",
    "ex3 = next(it3)\n",
    "ex3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "ce0f4c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(keras.Input(shape=(14,129)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256,  activation=\"sigmoid\"))\n",
    "model.add(Dense(128, activation=\"sigmoid\"))\n",
    "model.add(Dense(5*2000))\n",
    "model.add(Activation(activation=\"softmax\"))\n",
    "model.add(Flatten())\n",
    "model.add(Reshape((2000,5)))\n",
    "#model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "a624d971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' model = Sequential()\\nmodel.add(keras.Input(shape=(14,129)))\\nmodel.add(Conv2D(32, 5, strides=2, activation=\"relu\"))\\nmodel.add(Conv2D(32, 3, activation=\"relu\"))\\nmodel.add(MaxPooling2D(3))\\nmodel.add(Flatten())\\nmodel.add(Dense(250, activation=\"relu\"))\\nmodel.add(Dense(100, activation=\"relu\"))\\nmodel.add(Dense(2))\\nmodel.summary() '"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" model = Sequential()\n",
    "model.add(keras.Input(shape=(14,129)))\n",
    "model.add(Conv2D(32, 5, strides=2, activation=\"relu\"))\n",
    "model.add(Conv2D(32, 3, activation=\"relu\"))\n",
    "model.add(MaxPooling2D(3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation=\"relu\"))\n",
    "model.add(Dense(100, activation=\"relu\"))\n",
    "model.add(Dense(2))\n",
    "model.summary() \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "e31352cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" model = models.Sequential([\\n    layers.Input(shape=(14,129)),\\n    # Downsample the input.\\n    layers.Resizing(32, 32),\\n    # Normalize.\\n    norm_layer,\\n    layers.Conv2D(32, 3, activation='relu'),\\n    layers.Conv2D(64, 3, activation='relu'),\\n    layers.MaxPooling2D(),\\n    layers.Dropout(0.25),\\n    layers.Flatten(),\\n    layers.Dense(128, activation='relu'),\\n    layers.Dropout(0.5),\\n    layers.Dense(num_labels),\\n]) \""
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" model = models.Sequential([\n",
    "    layers.Input(shape=(14,129)),\n",
    "    # Downsample the input.\n",
    "    layers.Resizing(32, 32),\n",
    "    # Normalize.\n",
    "    norm_layer,\n",
    "    layers.Conv2D(32, 3, activation='relu'),\n",
    "    layers.Conv2D(64, 3, activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Dropout(0.25),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(num_labels),\n",
    "]) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10, 2000, 5])"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o= model(ex3[0])\n",
    "o.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "dd7a8c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_92\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_82 (Flatten)        (None, 1806)              0         \n",
      "                                                                 \n",
      " dense_268 (Dense)           (None, 256)               462592    \n",
      "                                                                 \n",
      " dense_269 (Dense)           (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_270 (Dense)           (None, 10000)             1290000   \n",
      "                                                                 \n",
      " activation_57 (Activation)  (None, 10000)             0         \n",
      "                                                                 \n",
      " flatten_83 (Flatten)        (None, 10000)             0         \n",
      "                                                                 \n",
      " reshape_65 (Reshape)        (None, 2000, 5)           0         \n",
      "                                                                 \n",
      " flatten_84 (Flatten)        (None, 10000)             0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,785,488\n",
      "Trainable params: 1,785,488\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b91856",
   "metadata": {},
   "source": [
    "lstm_model = tf.keras.models.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
    "    tf.keras.layers.LSTM(32, return_sequences=True),\n",
    "    # Shape => [batch, time, features]\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "9a83b7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'Equal_2' defined at (most recent call last):\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\traitlets\\config\\application.py\", line 972, in launch_instance\n      app.start()\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\asyncio\\base_events.py\", line 539, in run_forever\n      self._run_once()\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\asyncio\\base_events.py\", line 1775, in _run_once\n      handle._run()\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\asyncio\\events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 504, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 493, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 400, in dispatch_shell\n      await result\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 724, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 387, in do_execute\n      cell_id=cell_id,\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2975, in run_cell\n      raw_cell, store_history, silent, shell_futures, cell_id\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3029, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3257, in run_cell_async\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3472, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3552, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\ggpt9\\AppData\\Local\\Temp\\ipykernel_3028\\215431863.py\", line 9, in <module>\n      epochs=EPOCHS)\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\", line 894, in train_step\n      return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\", line 987, in compute_metrics\n      self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 501, in update_state\n      metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\utils\\metrics_utils.py\", line 70, in decorated\n      update_op = update_state_fn(*args, **kwargs)\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\metrics\\base_metric.py\", line 140, in update_state_fn\n      return ag_update_state(*args, **kwargs)\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\metrics\\base_metric.py\", line 646, in update_state\n      matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\utils\\metrics_utils.py\", line 893, in sparse_categorical_matches\n      matches = tf.cast(tf.equal(y_true, y_pred), backend.floatx())\nNode: 'Equal_2'\nIncompatible shapes: [10] vs. [10,2000]\n\t [[{{node Equal_2}}]] [Op:__inference_train_function_155537]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3028\\215431863.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \tmetrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n\u001b[0;32m      8\u001b[0m H = model.fit(dataset_pb_train,\n\u001b[1;32m----> 9\u001b[1;33m     epochs=EPOCHS)\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 55\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'Equal_2' defined at (most recent call last):\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\traitlets\\config\\application.py\", line 972, in launch_instance\n      app.start()\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\asyncio\\base_events.py\", line 539, in run_forever\n      self._run_once()\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\asyncio\\base_events.py\", line 1775, in _run_once\n      handle._run()\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\asyncio\\events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 504, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 493, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 400, in dispatch_shell\n      await result\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 724, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 387, in do_execute\n      cell_id=cell_id,\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2975, in run_cell\n      raw_cell, store_history, silent, shell_futures, cell_id\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3029, in _run_cell\n      return runner(coro)\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3257, in run_cell_async\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3472, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3552, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\ggpt9\\AppData\\Local\\Temp\\ipykernel_3028\\215431863.py\", line 9, in <module>\n      epochs=EPOCHS)\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\", line 894, in train_step\n      return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\training.py\", line 987, in compute_metrics\n      self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 501, in update_state\n      metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\utils\\metrics_utils.py\", line 70, in decorated\n      update_op = update_state_fn(*args, **kwargs)\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\metrics\\base_metric.py\", line 140, in update_state_fn\n      return ag_update_state(*args, **kwargs)\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\metrics\\base_metric.py\", line 646, in update_state\n      matches = ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\utils\\metrics_utils.py\", line 893, in sparse_categorical_matches\n      matches = tf.cast(tf.equal(y_true, y_pred), backend.floatx())\nNode: 'Equal_2'\nIncompatible shapes: [10] vs. [10,2000]\n\t [[{{node Equal_2}}]] [Op:__inference_train_function_155537]"
     ]
    }
   ],
   "source": [
    "# train the model using SGD\n",
    "EPOCHS = 10\n",
    "\n",
    "print(\"[INFO] training network...\")\n",
    "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer='sgd',\n",
    "\tmetrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
    "H = model.fit(dataset_pb_train,\n",
    "    epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e93cdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen, embed_dim):\n",
    "        super(PositionEmbedding, self).__init__()\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[1]\n",
    "        batchS = tf.shape(x)[0]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        positions = tf.expand_dims(positions, axis = 0)\n",
    "        positions = tf.repeat(positions, batchS, axis=0)\n",
    "        return x + positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092b8f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27471256",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15132\\623720847.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0minputA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0minputB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m129\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0membDim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#processa o input b e faz o upsampling e corta ao tamanho do target\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "inputA = keras.Input(shape=([]))\n",
    "inputB = keras.Input(shape=([None, 129]))\n",
    "embDim = 10\n",
    "\n",
    "#processa o input b e faz o upsampling e corta ao tamanho do target\n",
    "newEmb = layers.TimeDistributed(layers.Dense(embDim))(inputB)\n",
    "inputsPosEmb = PositionEmbedding(maxlen=20, embed_dim=embDim)(newEmb)\n",
    "transf1 = TransformerBlock(embed_dim=embDim,num_heads=3, ff_dim=8)(inputsPosEmb)\n",
    "transf2 =TransformerBlock(embed_dim=embDim,num_heads=3, ff_dim=8)(transf1)\n",
    "out = layers.TimeDistributed(layers.Dense(3))(transf2)\n",
    "#TODO insert LSTM here?\n",
    "\n",
    "transf_model = keras.Model(inputs=inputB, outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2f5bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 207, 129)\n"
     ]
    }
   ],
   "source": [
    "print(list(dataset3)[0][0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab0205d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1.0e-4\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "transf_model.compile(optimizer=opt, loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                    metrics = 'accuracy')\n",
    "transf_model.fit(inputsData, targets, batch_size=4, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945a4bd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e833a978",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = history.history\n",
    "plt.plot(history.epoch, metrics['loss'], metrics['val_loss'])\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd285dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "o= model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e7ec39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a4dbc77",
   "metadata": {},
   "source": [
    "sinal com tamanho inicial, "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "35212bcf1fad822c13ce98116127f99553f826fe8940f382348f125fcf46eb6b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
