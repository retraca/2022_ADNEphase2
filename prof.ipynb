{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7d5862e",
   "metadata": {},
   "source": [
    "# Usar um pipeline para ler e processar um conjunto de ficheiros e usar esse mesmo pipeline como 'conjunto de treino' #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4d547269",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "plt.style.use('seaborn-poster')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2971eed2",
   "metadata": {},
   "source": [
    "A api, tf.data.Dataset , permite criar um pipeline de leitura de ficheiros e seu eventual processamento, usando a função 'map':\n",
    "https://www.tensorflow.org/guide/data\n",
    ",\n",
    "https://www.tensorflow.org/guide/data_performance\n",
    ".\n",
    "\n",
    "Podemos fornecer diretamente um tfdata.Dataset ao método fit é uma forma muito eficiente de efetuar o treino de um modelo keras: https://www.tensorflow.org/guide/keras/train_and_evaluate#training_evaluation_from_tfdata_datasets\n",
    "\n",
    "\n",
    "No que se segue exemplificaremos a utilização desta api num conjunto de ficheiros do 2ª trabalho. O tf.data.Dataset permite criar 'batches' que podem sevir de inputs e labels a um modelo keras que faça a segmentação dos sons cardíacos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "aae2c616",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = './data/validacaoAlunos/'\n",
    "list_npy_files = glob.glob(dir + '*.npy')\n",
    "fnames_dataset = tf.data.Dataset.from_tensor_slices(list_npy_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8d112146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.string, name=None)>\n"
     ]
    }
   ],
   "source": [
    "print(fnames_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad940278",
   "metadata": {},
   "source": [
    "Podemos aceder um a um aos elementos (ou batches de elementos) de um dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "970b5e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'./data/validacaoAlunos\\\\14998_PV_sigTarg.npy'>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it = iter(fnames_dataset)\n",
    "ex = next(it)\n",
    "ex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460a7bfa",
   "metadata": {},
   "source": [
    "A partir deste dataset inicial, fnames_dataset, vamos criar um cujo conteudo é o resultado de ler cada um dos ficheiros npy.\n",
    "\n",
    "Começamos por uma função auxiliar que vai ser usada pela função 'map' para ler o conteúdo de cada um dos ficheiros do fnames_dataset e criar um novo dataset com estes conteúdos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6ce321bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_npy(fname):\n",
    "    \"\"\"fname should be a npy file\"\"\"\n",
    "    fname = fname.decode()\n",
    "    recData = np.load(fname)\n",
    "    return recData.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "69f44ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_raw = fnames_dataset.map(lambda x: tf.numpy_function(read_npy, [x], [tf.float32]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28da430",
   "metadata": {},
   "source": [
    "Poderiamos também usar a função 'map' para separar inputs e targets e obter um dataset que produz um 'tuple', (input, target) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e1de9f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((<tf.Tensor: shape=(), dtype=int32, numpy=25435>,\n",
       "  <tf.Tensor: shape=(197, 129), dtype=complex64, numpy=\n",
       "  array([[-9.2504510e+02+0.00000000e+00j, -2.5206216e+03+9.34842773e+03j,\n",
       "           7.7033047e+03-2.93779541e+03j, ...,\n",
       "          -1.2470239e+02-3.29393311e+01j, -1.8242554e+01-1.16825195e+02j,\n",
       "           2.4242975e+02+0.00000000e+00j],\n",
       "         [ 8.4404658e+03+0.00000000e+00j,  3.1762125e+04+1.85271816e+04j,\n",
       "          -7.7123828e+04+4.90774531e+04j, ...,\n",
       "          -2.7286328e+02-1.40541016e+02j, -4.6508691e+02-9.62832031e+01j,\n",
       "           1.0056179e+03+0.00000000e+00j],\n",
       "         [ 1.3549773e+04+0.00000000e+00j,  1.6253398e+04-1.47566152e+04j,\n",
       "          -5.3920125e+04-7.76776250e+04j, ...,\n",
       "          -4.6308789e+02+2.09753906e+02j, -9.8410645e+01+8.70815430e+01j,\n",
       "           6.1733789e+02+0.00000000e+00j],\n",
       "         ...,\n",
       "         [-1.0518837e+04+0.00000000e+00j,  8.6715977e+03-1.49277891e+04j,\n",
       "           2.9549316e+03+1.47093398e+04j, ...,\n",
       "          -2.1637695e+01-4.82548828e+01j,  2.1003418e+01-7.86132812e-01j,\n",
       "           7.2763672e+00+0.00000000e+00j],\n",
       "         [-7.2302607e+03+0.00000000e+00j, -1.0728717e+04-3.17502578e+04j,\n",
       "           5.3716461e+04+3.24250332e+04j, ...,\n",
       "          -1.4431445e+02-1.47089844e+01j,  7.5145020e+01+2.26328125e+01j,\n",
       "          -4.1949219e+01+0.00000000e+00j],\n",
       "         [ 5.7397573e+03+0.00000000e+00j, -1.9787777e+04-9.71893438e+04j,\n",
       "           7.5330328e+04+2.45365344e+05j, ...,\n",
       "          -1.9664062e+01+8.28906250e+01j, -3.9746094e-01-3.05000000e+01j,\n",
       "           1.3792480e+01+0.00000000e+00j]], dtype=complex64)>),\n",
       " <tf.Tensor: shape=(25435,), dtype=float32, numpy=array([4., 4., 4., ..., 1., 1., 1.], dtype=float32)>)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2x = dataset_raw.map(lambda x: (x[0],x[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea63d2bb",
   "metadata": {},
   "source": [
    "O nosso dataset pode também produzir 'batches' em vez de exemplos individuais.  No nosso caso os exempos não tẽm todos o mesmo comprimento, assim, teremos de extender(por zeros??) os exemplos mais curtos de cada batch de modo a todos os exemplos do mesmo batch terem o mesmo comprimento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec4ca4b",
   "metadata": {},
   "source": [
    "    Poderiamos também usar a função map para aplicar a 'stft' aos inputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d273a6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomExtract(x):\n",
    "    length = tf.shape(x)[1]\n",
    "    init = tf.random.uniform([], minval=0,maxval=length-L,dtype=tf.dtypes.int32)\n",
    "    return x[:, init:init+L]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "db4c5d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_length= 1000\n",
    "frame_step = 10\n",
    "\n",
    "def stft(x):\n",
    "    return tf.signal.stft(\n",
    "    x,\n",
    "    frame_length,\n",
    "    frame_step,\n",
    "    fft_length=None,\n",
    "    window_fn=tf.signal.hann_window,\n",
    "    pad_end=False,\n",
    "    name=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2f70ad0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_stft = dataset_raw.map(lambda x: ((tf.shape(x)[1],tf.signal.stft(x[0], 256,128)),x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "dbc1f71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(25435, shape=(), dtype=int32)\n",
      "(197, 129)\n",
      "tf.Tensor(26714, shape=(), dtype=int32)\n",
      "(207, 129)\n"
     ]
    }
   ],
   "source": [
    "print(list(dataset_stft)[0][0][0])\n",
    "print(list(dataset_stft)[0][0][1].shape)\n",
    "print(list(dataset_stft)[1][0][0])\n",
    "print(list(dataset_stft)[1][0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "dbe91b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((<tf.Tensor: shape=(2,), dtype=int32, numpy=array([25435, 26714])>,\n",
       "  <tf.Tensor: shape=(2, 207, 129), dtype=complex64, numpy=\n",
       "  array([[[-9.2504510e+02+0.00000000e+00j, -2.5206216e+03+9.34842773e+03j,\n",
       "            7.7033047e+03-2.93779541e+03j, ...,\n",
       "           -1.2470239e+02-3.29393311e+01j, -1.8242554e+01-1.16825195e+02j,\n",
       "            2.4242975e+02+0.00000000e+00j],\n",
       "          [ 8.4404658e+03+0.00000000e+00j,  3.1762125e+04+1.85271816e+04j,\n",
       "           -7.7123828e+04+4.90774531e+04j, ...,\n",
       "           -2.7286328e+02-1.40541016e+02j, -4.6508691e+02-9.62832031e+01j,\n",
       "            1.0056179e+03+0.00000000e+00j],\n",
       "          [ 1.3549773e+04+0.00000000e+00j,  1.6253398e+04-1.47566152e+04j,\n",
       "           -5.3920125e+04-7.76776250e+04j, ...,\n",
       "           -4.6308789e+02+2.09753906e+02j, -9.8410645e+01+8.70815430e+01j,\n",
       "            6.1733789e+02+0.00000000e+00j],\n",
       "          ...,\n",
       "          [ 0.0000000e+00+0.00000000e+00j,  0.0000000e+00+0.00000000e+00j,\n",
       "            0.0000000e+00+0.00000000e+00j, ...,\n",
       "            0.0000000e+00+0.00000000e+00j,  0.0000000e+00+0.00000000e+00j,\n",
       "            0.0000000e+00+0.00000000e+00j],\n",
       "          [ 0.0000000e+00+0.00000000e+00j,  0.0000000e+00+0.00000000e+00j,\n",
       "            0.0000000e+00+0.00000000e+00j, ...,\n",
       "            0.0000000e+00+0.00000000e+00j,  0.0000000e+00+0.00000000e+00j,\n",
       "            0.0000000e+00+0.00000000e+00j],\n",
       "          [ 0.0000000e+00+0.00000000e+00j,  0.0000000e+00+0.00000000e+00j,\n",
       "            0.0000000e+00+0.00000000e+00j, ...,\n",
       "            0.0000000e+00+0.00000000e+00j,  0.0000000e+00+0.00000000e+00j,\n",
       "            0.0000000e+00+0.00000000e+00j]],\n",
       "  \n",
       "         [[ 1.2886848e+04+0.00000000e+00j, -1.9009086e+04-1.59636709e+04j,\n",
       "            8.5916758e+03+5.10003613e+03j, ...,\n",
       "           -7.4447266e+01-3.58845215e+01j,  8.1539062e+01+2.26386719e+01j,\n",
       "           -7.4667480e+01+0.00000000e+00j],\n",
       "          [ 1.1631939e+04+0.00000000e+00j, -4.1416715e+04-4.59362891e+04j,\n",
       "            9.2780586e+04+6.96341953e+04j, ...,\n",
       "            8.6796875e+00-2.11015625e+01j, -3.3552734e+01-1.43828125e+01j,\n",
       "            5.7697266e+01+0.00000000e+00j],\n",
       "          [-7.8098555e+03+0.00000000e+00j, -1.7691646e+03+1.84997109e+04j,\n",
       "           -1.1077817e+04+3.72571094e+04j, ...,\n",
       "           -8.8599609e+01+3.51035156e+01j,  3.5606201e+01+2.43750000e+00j,\n",
       "           -3.4177246e+00+0.00000000e+00j],\n",
       "          ...,\n",
       "          [-1.2292781e+04+0.00000000e+00j, -5.3237603e+03-1.69346504e+04j,\n",
       "            1.8599770e+04+2.16494165e+03j, ...,\n",
       "            2.0626953e+01-3.65874023e+01j,  2.4331055e+00-2.49228516e+01j,\n",
       "           -2.4880371e+01+0.00000000e+00j],\n",
       "          [ 7.2889639e+03+0.00000000e+00j, -9.4020078e+03+2.04828293e+02j,\n",
       "            3.7961688e+04+6.95505156e+04j, ...,\n",
       "            6.6406250e-01-2.60195312e+01j, -2.6115234e+01+3.69918060e+01j,\n",
       "            2.3469727e+01+0.00000000e+00j],\n",
       "          [-1.5308815e+03+0.00000000e+00j,  2.3860248e+04-2.36150352e+04j,\n",
       "           -7.2836844e+04+2.48816406e+04j, ...,\n",
       "            1.2140625e+01+9.52539062e+00j,  1.6857422e+01-2.57285156e+01j,\n",
       "           -2.3094360e+01+0.00000000e+00j]]], dtype=complex64)>),\n",
       " <tf.Tensor: shape=(2, 26714), dtype=float32, numpy=\n",
       " array([[4., 4., 4., ..., 0., 0., 0.],\n",
       "        [4., 4., 4., ..., 3., 3., 3.]], dtype=float32)>)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 2\n",
    "k=129\n",
    "dataset_pb = dataset_stft.padded_batch(batch_size, padded_shapes=(([], tf.TensorShape([None, k])),[None,]))\n",
    "\n",
    "it3 = iter(dataset_pb)\n",
    "ex3 = next(it3)\n",
    "ex3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "773b3e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 26714)\n"
     ]
    }
   ],
   "source": [
    "print(ex3[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "47129361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 207, 129)\n",
      "(2, 240, 129)\n"
     ]
    }
   ],
   "source": [
    "print(list(dataset3)[0][0][1].shape)\n",
    "print(list(dataset3)[1][0][1].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "72b91856",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = tf.keras.models.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
    "    tf.keras.layers.LSTM(32, return_sequences=True),\n",
    "    # Shape => [batch, time, features]\n",
    "    tf.keras.layers.Dense(units=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6e93cdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionEmbedding(layers.Layer):\n",
    "    def __init__(self, maxlen, embed_dim):\n",
    "        super(PositionEmbedding, self).__init__()\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[1]\n",
    "        batchS = tf.shape(x)[0]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        positions = tf.expand_dims(positions, axis = 0)\n",
    "        positions = tf.repeat(positions, batchS, axis=0)\n",
    "        return x + positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "092b8f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "27471256",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputA = keras.Input(shape=([]))\n",
    "inputB = keras.Input(shape=([None, 129]))\n",
    "embDim = 10\n",
    "\n",
    "#processa o input b e faz o upsampling e corta ao tamanho do target\n",
    "\n",
    "newEmb = layers.TimeDistributed(layers.Dense(embDim))(inputB)\n",
    "inputsPosEmb = PositionEmbedding(maxlen=20, embed_dim=embDim)(newEmb)\n",
    "transf1 = TransformerBlock(embed_dim=embDim,num_heads=3, ff_dim=8)(inputsPosEmb)\n",
    "transf2 =TransformerBlock(embed_dim=embDim,num_heads=3, ff_dim=8)(transf1)\n",
    "out = layers.TimeDistributed(layers.Dense(3))(transf2)\n",
    "#TODO insert LSTM here?\n",
    "\n",
    "transf_model = keras.Model(inputs=inputB, outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1f2f5bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 207, 129)\n"
     ]
    }
   ],
   "source": [
    "print(list(dataset3)[0][0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a989f026",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "Exception encountered when calling layer \"embedding_4\" (type Embedding).\n\nindices[20] = 20 is not in [0, 20) [Op:ResourceGather]\n\nCall arguments received by layer \"embedding_4\" (type Embedding):\n  • inputs=tf.Tensor(shape=(207,), dtype=int32)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14824\\2693141507.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mo\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mtransf_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mex3\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\ggpt9\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14824\\1463308674.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mbatchS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mpositions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mpositions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_emb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpositions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mpositions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpositions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mpositions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpositions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatchS\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Exception encountered when calling layer \"embedding_4\" (type Embedding).\n\nindices[20] = 20 is not in [0, 20) [Op:ResourceGather]\n\nCall arguments received by layer \"embedding_4\" (type Embedding):\n  • inputs=tf.Tensor(shape=(207,), dtype=int32)"
     ]
    }
   ],
   "source": [
    "o= transf_model(ex3[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd285dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "o= model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e7ec39",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1.0e-4\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "transf_model.compile(optimizer=opt, loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                    metrics = 'accuracy')\n",
    "transf_model.fit(inputsData, targets, batch_size=4, epochs = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4dbc77",
   "metadata": {},
   "source": [
    "sinal com tamanho inicial, "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "35212bcf1fad822c13ce98116127f99553f826fe8940f382348f125fcf46eb6b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
