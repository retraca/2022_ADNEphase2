{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7d5862e",
   "metadata": {},
   "source": [
    "# Usar um pipeline para ler e processar um conjunto de ficheiros e usar esse mesmo pipeline como 'conjunto de treino' #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d547269",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 14:16:21.106765: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2971eed2",
   "metadata": {},
   "source": [
    "A api, tf.data.Dataset , permite criar um pipeline de leitura de ficheiros e seu eventual processamento, usando a função 'map':\n",
    "https://www.tensorflow.org/guide/data\n",
    ",\n",
    "https://www.tensorflow.org/guide/data_performance\n",
    ".\n",
    "\n",
    "Podemos fornecer diretamente um tfdata.Dataset ao método fit é uma forma muito eficiente de efetuar o treino de um modelo keras: https://www.tensorflow.org/guide/keras/train_and_evaluate#training_evaluation_from_tfdata_datasets\n",
    "\n",
    "\n",
    "No que se segue exemplificaremos a utilização desta api num conjunto de ficheiros do 2ª trabalho. O tf.data.Dataset permite criar 'batches' que podem sevir de inputs e labels a um modelo keras que faça a segmentação dos sons cardíacos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aae2c616",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 14:16:22.041032: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2022-05-06 14:16:22.090428: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 14:16:22.090632: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: GeForce GTX 1660 computeCapability: 7.5\n",
      "coreClock: 1.815GHz coreCount: 22 deviceMemorySize: 5.80GiB deviceMemoryBandwidth: 178.86GiB/s\n",
      "2022-05-06 14:16:22.090648: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-05-06 14:16:22.092238: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2022-05-06 14:16:22.092267: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2022-05-06 14:16:22.092943: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2022-05-06 14:16:22.093089: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2022-05-06 14:16:22.093714: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2022-05-06 14:16:22.094097: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-05-06 14:16:22.094172: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-05-06 14:16:22.094235: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 14:16:22.095078: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 14:16:22.095336: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2022-05-06 14:16:22.095757: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-05-06 14:16:22.096528: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 14:16:22.096915: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: GeForce GTX 1660 computeCapability: 7.5\n",
      "coreClock: 1.815GHz coreCount: 22 deviceMemorySize: 5.80GiB deviceMemoryBandwidth: 178.86GiB/s\n",
      "2022-05-06 14:16:22.096982: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 14:16:22.097192: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 14:16:22.097363: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2022-05-06 14:16:22.097392: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-05-06 14:16:22.426535: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-05-06 14:16:22.426553: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2022-05-06 14:16:22.426558: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2022-05-06 14:16:22.426682: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 14:16:22.426888: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 14:16:22.427080: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-05-06 14:16:22.427325: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 679 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1660, pci bus id: 0000:01:00.0, compute capability: 7.5)\n"
     ]
    }
   ],
   "source": [
    "dir = './'\n",
    "list_npy_files = glob.glob(dir + '*.npy')\n",
    "fnames_dataset = tf.data.Dataset.from_tensor_slices(list_npy_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad940278",
   "metadata": {},
   "source": [
    "Podemos aceder um a um aos elementos (ou batches de elementos) de um dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "970b5e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=string, numpy=b'./2530_MV_sigTarg.npy'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it = iter(fnames_dataset)\n",
    "ex = next(it)\n",
    "ex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460a7bfa",
   "metadata": {},
   "source": [
    "A partir deste dataset inicial, fnames_dataset, vamos criar um cujo conteudo é o resultado de ler cada um dos ficheiros npy.\n",
    "\n",
    "Começamos por uma função auxiliar que vai ser usada pela função 'map' para ler o conteúdo de cada um dos ficheiros do fnames_dataset e criar um novo dataset com estes conteúdos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ce321bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_npy(fname):\n",
    "    \"\"\"fname should be a npy file\"\"\"\n",
    "    fname = fname.decode()\n",
    "    recData = np.load(fname)\n",
    "    return recData.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69f44ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = fnames_dataset.map(lambda x: tf.numpy_function(read_npy, [x], [tf.float32]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6af290a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 14:16:22.467116: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-05-06 14:16:22.467360: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 3199980000 Hz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 48069), dtype=float32, numpy=\n",
       " array([[  52.,  -17., -185., ..., -353., -381., -411.],\n",
       "        [   0.,    0.,    0., ...,    4.,    4.,    4.]], dtype=float32)>,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it1 = iter(dataset)\n",
    "ex1 = next(it1)\n",
    "ex1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28da430",
   "metadata": {},
   "source": [
    "Poderiamos também usar a função 'map' para separar inputs e targets e obter um dataset que produz um 'tuple', (input, target) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1de9f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(48069,), dtype=float32, numpy=array([  52.,  -17., -185., ..., -353., -381., -411.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(48069,), dtype=float32, numpy=array([0., 0., 0., ..., 4., 4., 4.], dtype=float32)>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset2 = dataset.map(lambda x: (x[0],x[1]))\n",
    "it2 = iter(dataset2)\n",
    "ex2 = next(it2)\n",
    "ex2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea63d2bb",
   "metadata": {},
   "source": [
    "O nosso dataset pode também produzir 'batches' em vez de exemplos individuais.  No nosso caso os exempos não tẽm todos o mesmo comprimento, assim, teremos de extender(por zeros??) os exemplos mais curtos de cada batch de modo a todos os exemplos do mesmo batch terem o mesmo comprimento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96cc3c1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 48475), dtype=float32, numpy=\n",
       " array([[  52.,  -17., -185., ...,    0.,    0.,    0.],\n",
       "        [ 115., -208., -297., ...,   15.,  281.,  314.]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(2, 48475), dtype=float32, numpy=\n",
       " array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 4., 4., 0.]], dtype=float32)>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 2\n",
    "dataset3 = dataset2.padded_batch(batch_size, padded_shapes=([None,],[None,]))\n",
    "it3 = iter(dataset3)\n",
    "ex3 = next(it3)\n",
    "ex3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec4ca4b",
   "metadata": {},
   "source": [
    "    Poderiamos também usar a função map para aplicar a 'stft' aos inputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d273a6f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
